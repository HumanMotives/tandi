<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Moment/Place MVP</title>
  <style>
    body { display:flex; flex-direction:column; align-items:center; justify-content:center; height:100vh; margin:0; font-family:sans-serif; background:#f5f5f5; }
    h1 { margin-bottom:1rem; }
    button { padding:1rem 2rem; font-size:1rem; }
    progress { width:80%; margin-top:2rem; height:1rem; }
  </style>
</head>
<body>
  <h1 id="title">Record Moment 1</h1>
  <button id="recordBtn">Hold to Record</button>
  <progress id="progress" value="0" max="100" hidden></progress>

  <script>
    let audioCtx, micStream, recorder;
    let chunks = [], buffers = [], current = 0;
    const titleEl = document.getElementById('title');
    const btn = document.getElementById('recordBtn');
    const progress = document.getElementById('progress');

    async function initAudio() {
      audioCtx = new (window.AudioContext||window.webkitAudioContext)();
      micStream = await navigator.mediaDevices.getUserMedia({ audio:true });
    }

    async function startRecording() {
      // resume on first gesture for iOS
      if (audioCtx.state === 'suspended') await audioCtx.resume();

      if (!recorder) {
        recorder = new MediaRecorder(micStream);
        recorder.ondataavailable = e => chunks.push(e.data);
        recorder.onstop = async () => {
          // decode, store buffer
          const blob = new Blob(chunks, { type:'audio/webm' });
          chunks = [];
          const buf = await blob.arrayBuffer();
          const audioBuffer = await audioCtx.decodeAudioData(buf);
          buffers.push(audioBuffer);
          current++;
          if (current < 3) {
            titleEl.textContent = `Record Moment ${current+1}`;
          } else {
            showProgressBar();
            await delay(2000);
            playAmbient();
          }
        };
      }
      recorder.start();
    }

    function stopRecording() {
      if (recorder && recorder.state === 'recording') recorder.stop();
    }

    function showProgressBar() {
      btn.hidden = true;
      progress.hidden = false;
      let val = 0;
      const iv = setInterval(() => {
        val += 10;
        progress.value = val;
        if (val >= 100) clearInterval(iv);
      }, 200);
    }

    function delay(ms){ return new Promise(res=>setTimeout(res, ms)); }

    function playAmbient() {
      const masterGain = audioCtx.createGain();
      masterGain.gain.value = 0.5;
      masterGain.connect(audioCtx.destination);

      // simple reverb stub: you can load an IR later
      // const convolver = audioCtx.createConvolver();
      // masterGain.connect(convolver).connect(audioCtx.destination);

      buffers.forEach(buffer => {
        const src = audioCtx.createBufferSource();
        src.buffer = buffer;
        src.loop = true;
        src.connect(masterGain);
        src.start();
      });
      titleEl.textContent = 'Here’s your Moment/Place ▶️';
    }

    // wire touch/mouse
    btn.addEventListener('touchstart', startRecording);
    btn.addEventListener('mousedown', startRecording);
    btn.addEventListener('touchend', stopRecording);
    btn.addEventListener('mouseup', stopRecording);

    // bootstrap
    initAudio().catch(e => alert('Mic access is required.'));
  </script>
</body>
</html>
